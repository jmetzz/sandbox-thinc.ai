{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've written a layer or model definition you're happy with, you can use Thinc's function registry to register it and assign it a string name. Your function can take any arguments that can later be defined in the config. Adding **type hints** ensures that config settings will be **parsed and validated** before they're passed into the function, so you don't end up with incompatible settings and confusing failures later on. Here's the MNIST model, defined as a custom layer:"
   ]
  },
  {
   "source": [
    "# Prepare the environment\n",
    "\n",
    "Install the dependencies and import the necessary packages.\n",
    "\n",
    "> GraphViz must be installed in your system in order to visualize the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Requirement already satisfied: thinc>=8.0.0a0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (8.0.0a1)\nRequirement already satisfied: ml_datasets in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (0.1.6)\nRequirement already satisfied: tqdm>=4.41 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (4.47.0)\nRequirement already satisfied: pydot in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (1.4.1)\nRequirement already satisfied: graphviz in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (0.14.1)\nRequirement already satisfied: svgwrite in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (1.4)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (3.0.2)\nRequirement already satisfied: srsly<3.0.0,>=2.0.0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (2.0.1)\nRequirement already satisfied: numpy>=1.7.0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (1.18.1)\nRequirement already satisfied: catalogue<3.0.0,>=0.2.0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (2.0.0)\nRequirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4.1; python_version < \"3.8\" in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (3.7.4.1)\nRequirement already satisfied: setuptools in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (47.1.1.post20200604)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (1.0.2)\nRequirement already satisfied: pydantic<2.0.0,>=1.4.0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (1.5.1)\nRequirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (0.6.0)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (2.0.3)\nRequirement already satisfied: pyparsing>=2.1.4 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from pydot) (2.4.7)\nRequirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from catalogue<3.0.0,>=0.2.0->thinc>=8.0.0a0) (1.6.0)\nRequirement already satisfied: zipp>=0.5 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<3.0.0,>=0.2.0->thinc>=8.0.0a0) (3.1.0)\n"
    }
   ],
   "source": [
    "!pip install \"thinc>=8.0.0a0\" ml_datasets \"tqdm>=4.41\" pydot graphviz svgwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from typing import Union, Iterable\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "import pydot\n",
    "from IPython.display import SVG, display\n",
    "\n",
    "import thinc\n",
    "from thinc.api import chain, Relu, Softmax, Config, registry\n",
    "from thinc.types import FloatsXd\n",
    "\n",
    "import ml_datasets\n"
   ]
  },
  {
   "source": [
    "# Utility functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(data, model, optimizer, n_iter, batch_size):\n",
    "    (train_X, train_Y), (test_X, test_Y) = data\n",
    "    for i in range(n_iter):\n",
    "        batches = model.ops.multibatch(batch_size, train_X, train_Y, shuffle=True)\n",
    "        for X, Y in tqdm(batches, leave=False):\n",
    "            Yh, backprop = model.begin_update(X)\n",
    "            backprop(Yh - Y)\n",
    "            model.finish_update(optimizer)\n",
    "        # Evaluate and print progress\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for X, Y in model.ops.multibatch(batch_size, test_X, test_Y):\n",
    "            Yh = model.predict(X)\n",
    "            correct += (Yh.argmax(axis=1) == Y.argmax(axis=1)).sum()\n",
    "            total += Yh.shape[0]\n",
    "        score = correct / total\n",
    "        print(f\" {i} {float(score):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_label(layer):\n",
    "    layer_name = layer.name\n",
    "    nO = layer.get_dim(\"nO\") if layer.has_dim(\"nO\") else \"?\"\n",
    "    nI = layer.get_dim(\"nI\") if layer.has_dim(\"nI\") else \"?\"\n",
    "    return f\"{layer.name}|({nI}, {nO})\".replace(\">\", \"&gt;\")\n",
    "\n",
    "def visualize_model(model):\n",
    "    dot = pydot.Dot()\n",
    "    dot.set(\"rankdir\", \"LR\")\n",
    "    dot.set_node_defaults(shape=\"record\", fontname=\"arial\", fontsize=\"10\")\n",
    "    dot.set_edge_defaults(arrowsize=\"0.7\")\n",
    "    nodes = {}\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        label = get_label(layer)\n",
    "        node = pydot.Node(layer.id, label=label)\n",
    "        dot.add_node(node)\n",
    "        nodes[layer.id] = node\n",
    "        if i == 0:\n",
    "            continue\n",
    "        from_node = nodes[model.layers[i - 1].id]\n",
    "        to_node = nodes[layer.id]\n",
    "        if not dot.get_edge(from_node, to_node):\n",
    "            dot.add_edge(pydot.Edge(from_node, to_node))\n",
    "    display(SVG(dot.create_svg()))"
   ]
  },
  {
   "source": [
    "# Create and register a custom optmizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MyCoolOptimizer(eta=2.0, gamma=3.0)\n"
    }
   ],
   "source": [
    "class MyCoolOptimizer():\n",
    "    def __init__(self, learn_rate: float, gamma: Iterable[float]):\n",
    "        self.eta = learn_rate\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"MyCoolOptimizer(eta={self.eta}, gamma={self.gamma})\"\n",
    "\n",
    "    def __call__(self, weights: FloatsXd, gradient: FloatsXd):\n",
    "        \"\"\"Call the optimizer with weights and a gradient. The key is the\n",
    "        identifier for the parameter, usually the node ID and parameter name.\n",
    "        \"\"\"\n",
    "        # the optimization logic goes here :)\n",
    "        param, grad =  self._my_cool_logic(weights, gradient)\n",
    "        return param, grad\n",
    "\n",
    "    def _my_cool_logic(self, weights, gradient):\n",
    "        #dummy placeholder\n",
    "        pass\n",
    "\n",
    "\n",
    "op = MyCoolOptimizer(2.0, 3.0)\n",
    "print(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<function __main__.make_my_optimizer(learn_rate: Union[float, Iterable[float]], gamma: float)>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "@thinc.registry.optimizers.register(\"my_cool_optimizer.v1\")\n",
    "def make_my_optimizer(learn_rate: Union[float, Iterable[float]], gamma: float):\n",
    "    return MyCoolOptimizer(learn_rate, gamma)\n",
    "\n",
    "# Later you can retrieve your function by name:\n",
    "create_optimizer = thinc.registry.optimizers.get(\"my_cool_optimizer.v1\")\n",
    "create_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@thinc.registry.schedules(\"my_cool_decaying_schedule.v1\")\n",
    "def decaying(base_rate: float, decay: float, *, t: int = 0) -> Iterable[float]:\n",
    "    while True:\n",
    "        yield base_rate * (1.0 / (1.0 + decay * t))\n",
    "        t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "MyCoolOptimizer(eta=<generator object decaying at 0x7f7fc0a4f9d0>, gamma=1e-08)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "CONFIG = \"\"\"[optimizer]\n",
    "@optimizers = \"my_cool_optimizer.v1\"\n",
    "gamma = 1e-8\n",
    "\n",
    "[optimizer.learn_rate]\n",
    "@schedules = \"my_cool_decaying_schedule.v1\"\n",
    "base_rate = 0.001\n",
    "decay = 1e-4\n",
    "\"\"\"\n",
    "\n",
    "config = Config().from_str(CONFIG)\n",
    "C = registry.make_from_config(config)\n",
    "C['optimizer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable positional arguments example\n",
    "\n",
    "In some cases your registered function may accept variable positional arguments. In your config, you can then use `*` to define a list of values:\n",
    "\n",
    "```yaml\n",
    "[schedule]\n",
    "@schedules = \"my_cool_schedule.v1\"\n",
    "* = [0.05, 0.1, 0.25, 0.75, 0.9]\n",
    "final = 1.0\n",
    "```\n",
    "\n",
    "\n",
    "> Type hints for variable arguments should always describe the type of the individual arguments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@thinc.registry.schedules(\"my_cool_schedule.v1\")\n",
    "def schedule(*steps: float, final: float = 1.0) -> Iterable[float]:\n",
    "    yield from steps\n",
    "    while True:\n",
    "        yield final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<generator object schedule at 0x7f7fc0a4fc50>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "CONFIG= \"\"\"[optimizer]\n",
    "@optimizers = \"my_cool_optimizer.v1\"\n",
    "gamma = 1e-8\n",
    "\n",
    "[optimizer.learn_rate]\n",
    "@schedules = \"my_cool_decaying_schedule.v1\"\n",
    "base_rate = 0.001\n",
    "decay = 1e-4\n",
    "\n",
    "[schedule]\n",
    "@schedules = \"my_cool_schedule.v1\"\n",
    "* = [0.05, 0.1, 0.25, 0.75, 0.9]\n",
    "final = 1.0\n",
    "\"\"\"\n",
    "config = Config().from_str(CONFIG)\n",
    "C = registry.make_from_config(config)\n",
    "my_schedule = C['schedule']\n",
    "my_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0.05, 0.1, 0.25, 0.75, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0]"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# print the first 10 elements of the `schedule` object\n",
    "list(itertools.islice(my_schedule, 10))"
   ]
  },
  {
   "source": [
    "# Register a model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@thinc.registry.layers(\"MNIST.v1\")\n",
    "def create_mnist(nO: int, dropout: float):\n",
    "    return chain(\n",
    "        Relu(nO, dropout=dropout), \n",
    "        Relu(nO, dropout=dropout), \n",
    "        Softmax()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the config, we can now refer to it by name and set its arguments. This makes the config maintainable and compact, while still allowing you to change and record the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'model': {'@layers': 'MNIST.v1', 'nO': 32, 'dropout': 0.2},\n 'optimizer': {'@optimizers': 'Adam.v1', 'learn_rate': 0.001},\n 'training': {'n_iter': 10, 'batch_size': 128}}"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "CONFIG = \"\"\"\n",
    "[model]\n",
    "@layers = \"MNIST.v1\"\n",
    "nO = 32\n",
    "dropout = 0.2\n",
    "\n",
    "[optimizer]\n",
    "@optimizers = \"Adam.v1\"\n",
    "learn_rate = 0.001\n",
    "\n",
    "[training]\n",
    "n_iter = 10\n",
    "batch_size = 128\n",
    "\"\"\"\n",
    "\n",
    "config = Config().from_str(CONFIG)\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also wrap the dataset in a registry function.\n",
    "Before make sure you have all the dependencies settled. For this example, install the `ml_datasets` package and import all the objects used in the configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@thinc.registry.datasets(\"mnist_data.v1\")\n",
    "def mnist():\n",
    "    return ml_datasets.mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'model': <thinc.model.Model at 0x7f7fc0a86950>,\n 'optimizer': <thinc.optimizers.Optimizer at 0x7f7fc0a9e260>,\n 'training': {'n_iter': 10,\n  'batch_size': 128,\n  'data': ((array([[0., 0., 0., ..., 0., 0., 0.],\n           [0., 0., 0., ..., 0., 0., 0.],\n           [0., 0., 0., ..., 0., 0., 0.],\n           ...,\n           [0., 0., 0., ..., 0., 0., 0.],\n           [0., 0., 0., ..., 0., 0., 0.],\n           [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n    array([[0., 0., 0., ..., 1., 0., 0.],\n           [0., 0., 0., ..., 0., 0., 0.],\n           [0., 0., 0., ..., 0., 0., 0.],\n           ...,\n           [0., 0., 0., ..., 1., 0., 0.],\n           [1., 0., 0., ..., 0., 0., 0.],\n           [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)),\n   (array([[0., 0., 0., ..., 0., 0., 0.],\n           [0., 0., 0., ..., 0., 0., 0.],\n           [0., 0., 0., ..., 0., 0., 0.],\n           ...,\n           [0., 0., 0., ..., 0., 0., 0.],\n           [0., 0., 0., ..., 0., 0., 0.],\n           [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n    array([[0., 0., 0., ..., 1., 0., 0.],\n           [0., 0., 1., ..., 0., 0., 0.],\n           [0., 1., 0., ..., 0., 0., 0.],\n           ...,\n           [0., 0., 0., ..., 0., 0., 0.],\n           [0., 0., 0., ..., 0., 0., 0.],\n           [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)))}}"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "CONFIG = \"\"\"\n",
    "[model]\n",
    "@layers = \"MNIST.v1\"\n",
    "nO = 32\n",
    "dropout = 0.2\n",
    "\n",
    "[optimizer]\n",
    "@optimizers = \"Adam.v1\"\n",
    "learn_rate = 0.001\n",
    "\n",
    "[training]\n",
    "n_iter = 10\n",
    "batch_size = 128\n",
    "\n",
    "[training.data]\n",
    "@datasets = \"mnist_data.v1\"\n",
    "\"\"\"\n",
    "\n",
    "config = Config().from_str(CONFIG)\n",
    "loaded_config = registry.make_from_config(config)\n",
    "loaded_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<thinc.model.Model at 0x7f7fc0a86950>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# Now you can use the objects in the registry:\n",
    "model = loaded_config[\"model\"]\n",
    "optimizer = loaded_config[\"optimizer\"]\n",
    "n_iter = loaded_config[\"training\"][\"n_iter\"]\n",
    "batch_size = loaded_config[\"training\"][\"batch_size\"]\n",
    "data = (train_X, train_Y), (dev_X, dev_Y) = loaded_config[\"training\"][\"data\"]\n",
    "\n",
    "# After loading the data from config, they might still need to be moved to the right device\n",
    "train_X = model.ops.asarray(train_X)\n",
    "train_Y = model.ops.asarray(train_Y)\n",
    "dev_X = model.ops.asarray(dev_X)\n",
    "dev_Y = model.ops.asarray(dev_Y)\n",
    "\n",
    "model.initialize(X=train_X[:5], Y=train_Y[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.SVG object>",
      "image/svg+xml": "<svg height=\"47pt\" viewBox=\"0.00 0.00 288.00 47.00\" width=\"288pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 43)\">\n<title>G</title>\n<polygon fill=\"white\" points=\"-4,4 -4,-43 284,-43 284,4 -4,4\" stroke=\"transparent\"/>\n<!-- 3 -->\n<g class=\"node\" id=\"node1\">\n<title>3</title>\n<polygon fill=\"none\" points=\"0,-0.5 0,-38.5 77,-38.5 77,-0.5 0,-0.5\" stroke=\"black\"/>\n<text font-family=\"arial\" font-size=\"10.00\" text-anchor=\"middle\" x=\"38.5\" y=\"-26.5\">relu&gt;&gt;dropout</text>\n<polyline fill=\"none\" points=\"0,-19.5 77,-19.5 \" stroke=\"black\"/>\n<text font-family=\"arial\" font-size=\"10.00\" text-anchor=\"middle\" x=\"38.5\" y=\"-7.5\">(784, 32)</text>\n</g>\n<!-- 6 -->\n<g class=\"node\" id=\"node2\">\n<title>6</title>\n<polygon fill=\"none\" points=\"113,-0.5 113,-38.5 190,-38.5 190,-0.5 113,-0.5\" stroke=\"black\"/>\n<text font-family=\"arial\" font-size=\"10.00\" text-anchor=\"middle\" x=\"151.5\" y=\"-26.5\">relu&gt;&gt;dropout</text>\n<polyline fill=\"none\" points=\"113,-19.5 190,-19.5 \" stroke=\"black\"/>\n<text font-family=\"arial\" font-size=\"10.00\" text-anchor=\"middle\" x=\"151.5\" y=\"-7.5\">(32, 32)</text>\n</g>\n<!-- 3&#45;&gt;6 -->\n<g class=\"edge\" id=\"edge1\">\n<title>3-&gt;6</title>\n<path d=\"M77.08,-19.5C86.3,-19.5 96.26,-19.5 105.78,-19.5\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"105.96,-21.95 112.96,-19.5 105.96,-17.05 105.96,-21.95\" stroke=\"black\"/>\n</g>\n<!-- 7 -->\n<g class=\"node\" id=\"node3\">\n<title>7</title>\n<polygon fill=\"none\" points=\"226,-0.5 226,-38.5 280,-38.5 280,-0.5 226,-0.5\" stroke=\"black\"/>\n<text font-family=\"arial\" font-size=\"10.00\" text-anchor=\"middle\" x=\"253\" y=\"-26.5\">softmax</text>\n<polyline fill=\"none\" points=\"226,-19.5 280,-19.5 \" stroke=\"black\"/>\n<text font-family=\"arial\" font-size=\"10.00\" text-anchor=\"middle\" x=\"253\" y=\"-7.5\">(32, 10)</text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g class=\"edge\" id=\"edge2\">\n<title>6-&gt;7</title>\n<path d=\"M190.12,-19.5C199.5,-19.5 209.49,-19.5 218.65,-19.5\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"218.78,-21.95 225.78,-19.5 218.78,-17.05 218.78,-21.95\" stroke=\"black\"/>\n</g>\n</g>\n</svg>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "visualize_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=422.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "acde536bef0a4af99cbb6729f11b14ab"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0 0.840\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=422.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "28600bba18034897a8a3f9405f80ae64"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1 0.879\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=422.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0517323d2f5742f0a4dda3785b0b8809"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2 0.893\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=422.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72efbdbd8eea42f78308b3fb9510a6bc"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "3 0.904\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=422.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6800be65cfc5411f83ee6f154cf14b4d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "4 0.912\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=422.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "028a3ec984e04d43865348c932d08a9e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "5 0.919\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=422.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b980a0b6597141daa9c16dc52abf73f1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "6 0.920\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=422.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2110cc042fd0479ba9c1b0a3f14ad5d5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "7 0.920\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=422.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7afe5cfbfe444a088aeb1af539711cf3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "8 0.926\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=422.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ac5bac9308f4b1db479c13aecffedcc"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "9 0.927\n"
    }
   ],
   "source": [
    "train_model(data, model, optimizer, n_iter, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}