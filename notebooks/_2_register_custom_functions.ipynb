{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've written a layer or model definition you're happy with, you can use Thinc's function registry to register it and assign it a string name. Your function can take any arguments that can later be defined in the config. Adding **type hints** ensures that config settings will be **parsed and validated** before they're passed into the function, so you don't end up with incompatible settings and confusing failures later on. Here's the MNIST model, defined as a custom layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import thinc\n",
    "\n",
    "@thinc.registry.layers(\"MNIST.v1\")\n",
    "def create_mnist(nO: int, dropout: float):\n",
    "    return chain(\n",
    "        Relu(nO, dropout=dropout), \n",
    "        Relu(nO, dropout=dropout), \n",
    "        Softmax()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the config, we can now refer to it by name and set its arguments. This makes the config maintainable and compact, while still allowing you to change and record the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': {'@layers': 'MNIST.v1', 'nO': 32, 'dropout': 0.2},\n",
       " 'optimizer': {'@optimizers': 'Adam.v1', 'learn_rate': 0.001},\n",
       " 'training': {'n_iter': 10, 'batch_size': 128}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from thinc.api import Config, registry\n",
    "\n",
    "CONFIG1 = \"\"\"\n",
    "[model]\n",
    "@layers = \"MNIST.v1\"\n",
    "nO = 32\n",
    "dropout = 0.2\n",
    "\n",
    "[optimizer]\n",
    "@optimizers = \"Adam.v1\"\n",
    "learn_rate = 0.001\n",
    "\n",
    "[training]\n",
    "n_iter = 10\n",
    "batch_size = 128\n",
    "\"\"\"\n",
    "\n",
    "config = Config().from_str(CONFIG1)\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also wrap the dataset in a registry function.\n",
    "Before make sure you have all the dependencies settled. For this example, install the `ml_datasets` package and import all the objects used in the configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ml_datasets in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.6/site-packages (0.1.6)\n",
      "Requirement already satisfied: numpy>=1.7.0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.6/site-packages (from ml_datasets) (1.18.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.6/site-packages (from ml_datasets) (4.44.1)\n",
      "Requirement already satisfied: catalogue<3.0.0,>=0.2.0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.6/site-packages (from ml_datasets) (2.0.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=1.0.1 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.6/site-packages (from ml_datasets) (2.0.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.6/site-packages (from catalogue<3.0.0,>=0.2.0->ml_datasets) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<3.0.0,>=0.2.0->ml_datasets) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ml_datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@thinc.registry.datasets(\"mnist_data.v1\")\n",
    "def mnist():\n",
    "    return ml_datasets.mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': <thinc.model.Model at 0x12df96f28>,\n",
       " 'optimizer': <thinc.optimizers.Optimizer at 0x12df9c780>,\n",
       " 'training': {'n_iter': 10,\n",
       "  'batch_size': 128,\n",
       "  'data': ((array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "           [0., 0., 0., ..., 0., 0., 0.],\n",
       "           [0., 0., 0., ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0., ..., 0., 0., 0.],\n",
       "           [0., 0., 0., ..., 0., 0., 0.],\n",
       "           [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       "    array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "           [0., 0., 0., ..., 0., 0., 0.],\n",
       "           [0., 0., 0., ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0., ..., 1., 0., 0.],\n",
       "           [0., 0., 1., ..., 0., 0., 0.],\n",
       "           [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)),\n",
       "   (array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "           [0., 0., 0., ..., 0., 0., 0.],\n",
       "           [0., 0., 0., ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0., ..., 0., 0., 0.],\n",
       "           [0., 0., 0., ..., 0., 0., 0.],\n",
       "           [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       "    array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "           [0., 0., 1., ..., 0., 0., 0.],\n",
       "           [0., 1., 0., ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0., ..., 0., 0., 0.],\n",
       "           [0., 0., 0., ..., 0., 0., 0.],\n",
       "           [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)))}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from thinc.api import chain, Relu, Softmax\n",
    "import ml_datasets\n",
    "\n",
    "\n",
    "CONFIG2 = \"\"\"\n",
    "[model]\n",
    "@layers = \"MNIST.v1\"\n",
    "nO = 32\n",
    "dropout = 0.2\n",
    "\n",
    "[optimizer]\n",
    "@optimizers = \"Adam.v1\"\n",
    "learn_rate = 0.001\n",
    "\n",
    "[training]\n",
    "n_iter = 10\n",
    "batch_size = 128\n",
    "\n",
    "[training.data]\n",
    "@datasets = \"mnist_data.v1\"\n",
    "\"\"\"\n",
    "\n",
    "config = Config().from_str(CONFIG2)\n",
    "loaded_config = registry.make_from_config(config)\n",
    "loaded_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretending to train the model ...\n",
      "Done pretending.\n"
     ]
    }
   ],
   "source": [
    "# Now you can use the objects in the registry:\n",
    "\n",
    "def train_model(data, model, optimizer, n_iter, batch_size):\n",
    "    print(\"Pretending to train the model ...\")\n",
    "    print(\"Done pretending.\")\n",
    "\n",
    "model = loaded_config[\"model\"]\n",
    "optimizer = loaded_config[\"optimizer\"]\n",
    "n_iter = loaded_config[\"training\"][\"n_iter\"]\n",
    "batch_size = loaded_config[\"training\"][\"batch_size\"]\n",
    "data = (train_X, train_Y), (dev_X, dev_Y) = loaded_config[\"training\"][\"data\"]\n",
    "\n",
    "# After loading the data from config, they might still need to be moved to the right device\n",
    "train_X = model.ops.asarray(train_X)\n",
    "train_Y = model.ops.asarray(train_Y)\n",
    "dev_X = model.ops.asarray(dev_X)\n",
    "dev_Y = model.ops.asarray(dev_Y)\n",
    "\n",
    "model.initialize(X=train_X[:5], Y=train_Y[:5])\n",
    "train_model(data, model, optimizer, n_iter, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thinc.ai] *",
   "language": "python",
   "name": "conda-env-thinc.ai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
