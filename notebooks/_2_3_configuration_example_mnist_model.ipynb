{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring the MNIST model\n",
    "\n",
    "Let's configure a model equivalent to \n",
    "\n",
    "```python\n",
    "n_hidden = 32\n",
    "dropout = 0.2\n",
    "model = chain(\n",
    "    Relu(nO=n_hidden, dropout=dropout), \n",
    "    Relu(nO=n_hidden, dropout=dropout), \n",
    "    Softmax()\n",
    ")\n",
    "``` \n",
    "\n",
    "Moreover, let's use Adam optimizer with `learn_rate = 0.001`, 10 iterations over batches of 128 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: thinc>=8.0.0a0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (8.0.0a1)\n",
      "Requirement already satisfied: ml_datasets in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (0.1.6)\n",
      "Requirement already satisfied: tqdm>=4.41 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (4.46.0)\n",
      "Requirement already satisfied: catalogue<3.0.0,>=0.2.0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (46.4.0.post20200518)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (2.0.3)\n",
      "Requirement already satisfied: pydantic<2.0.0,>=1.4.0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (1.5.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4.1; python_version < \"3.8\" in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (3.7.4.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (1.0.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (3.0.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.0.0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (2.0.1)\n",
      "Requirement already satisfied: numpy>=1.7.0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (1.18.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from catalogue<3.0.0,>=0.2.0->thinc>=8.0.0a0) (1.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<3.0.0,>=0.2.0->thinc>=8.0.0a0) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"thinc>=8.0.0a0\" ml_datasets \"tqdm>=4.41\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from thinc.api import prefer_gpu\n",
    "from thinc.api import Config, registry\n",
    "import ml_datasets\n",
    "\n",
    "# Perform operations on GPU if available\n",
    "prefer_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size=54000, test size=10000\n"
     ]
    }
   ],
   "source": [
    "# Get the dataset\n",
    "(train_X, train_Y), (test_X, test_Y) = ml_datasets.mnist()\n",
    "print(f\"Training size={len(train_X)}, test size={len(test_X)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hyper_params': {'n_hidden': 32, 'dropout': 0.2, 'learn_rate': 0.001},\n",
       " 'model': {'@layers': 'chain.v1',\n",
       "  '*': {'relu1': {'@layers': 'Relu.v1', 'nO': 32, 'dropout': 0.2},\n",
       "   'relu2': {'@layers': 'Relu.v1', 'nO': 32, 'dropout': 0.2},\n",
       "   'softmax': {'@layers': 'Softmax.v1'}}},\n",
       " 'optimizer': {'@optimizers': 'Adam.v1', 'learn_rate': 0.001},\n",
       " 'training': {'n_iter': 10, 'batch_size': 128}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG = \"\"\"\n",
    "[hyper_params]\n",
    "n_hidden = 32\n",
    "dropout = 0.2\n",
    "learn_rate = 0.001\n",
    "\n",
    "[model]\n",
    "@layers = \"chain.v1\"\n",
    "\n",
    "[model.*.relu1]\n",
    "@layers = \"Relu.v1\"\n",
    "nO = ${hyper_params:n_hidden}\n",
    "dropout = ${hyper_params:dropout}\n",
    "\n",
    "[model.*.relu2]\n",
    "@layers = \"Relu.v1\"\n",
    "nO = ${hyper_params:n_hidden}\n",
    "dropout = ${hyper_params:dropout}\n",
    "\n",
    "[model.*.softmax]\n",
    "@layers = \"Softmax.v1\"\n",
    "\n",
    "[optimizer]\n",
    "@optimizers = \"Adam.v1\"\n",
    "learn_rate = ${hyper_params:learn_rate}\n",
    "\n",
    "[training]\n",
    "n_iter = 10\n",
    "batch_size = 128\n",
    "\"\"\"\n",
    "\n",
    "config = Config().from_str(CONFIG)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hyper_params': {'n_hidden': 32, 'dropout': 0.2, 'learn_rate': 0.001},\n",
       " 'model': <thinc.model.Model at 0x14be839d8>,\n",
       " 'optimizer': <thinc.optimizers.Optimizer at 0x14be9d978>,\n",
       " 'training': {'n_iter': 10, 'batch_size': 128}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_config = registry.make_from_config(config)\n",
    "loaded_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "When you call registry.make_from_config, Thinc will first create the three layers using the specified \n",
    "arguments populated by the hyperparameters. It will then pass the return values (the layer objects) to chain. \n",
    "It will also create an optimizer. All other values, like the training config, will be passed through as a regular dict.\n",
    "Your training code can now look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<thinc.model.Model at 0x14be839d8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = loaded_config[\"model\"]\n",
    "optimizer = loaded_config[\"optimizer\"]\n",
    "n_iter = loaded_config[\"training\"][\"n_iter\"]\n",
    "batch_size = loaded_config[\"training\"][\"batch_size\"]\n",
    "\n",
    "\n",
    "# Make sure the data is on the right device\n",
    "train_X = model.ops.asarray(train_X)\n",
    "train_Y = model.ops.asarray(train_Y)\n",
    "dev_X = model.ops.asarray(test_X)\n",
    "dev_Y = model.ops.asarray(test_Y)\n",
    "\n",
    "# Initialize the model to infer the missing information\n",
    "model.initialize(X=train_X[:5], Y=train_Y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The function to train the model is defined in `src/train.py` module, which allows reusability.\n",
    "It's code is show here for the sake of clarity:\n",
    "\n",
    "```python\n",
    "def train_model(data, model, optimizer, n_iter, batch_size):\n",
    "    (train_X, train_Y), (test_X, test_Y) = data\n",
    "    indices = model.ops.xp.arange(train_X.shape[0], dtype=\"i\")\n",
    "    for i in range(n_iter):\n",
    "        batches = model.ops.multibatch(batch_size, train_X, train_Y, shuffle=True)\n",
    "        for X, Y in tqdm(batches, leave=False):\n",
    "            Yh, backprop = model.begin_update(X)\n",
    "            backprop(Yh - Y)\n",
    "            model.finish_update(optimizer)\n",
    "        # Evaluate and print progress\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for X, Y in model.ops.multibatch(batch_size, test_X, test_Y):\n",
    "            Yh = model.predict(X)\n",
    "            correct += (Yh.argmax(axis=1) == Y.argmax(axis=1)).sum()\n",
    "            total += Yh.shape[0]\n",
    "        score = correct / total\n",
    "        print(f\" {i} {float(score):.3f}\")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jean.metz/workspace/jmetzz/sandbox-thinc.ai\n",
      "['/Users/jean.metz/workspace/jmetzz/sandbox-thinc.ai/src', '/Users/jean.metz/workspace/jmetzz/sandbox-thinc.ai/notebooks', '/Users/jean.metz/miniconda/envs/thinc.ai/lib/python37.zip', '/Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7', '/Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/lib-dynload', '', '/Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages', '/Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages/IPython/extensions', '/Users/jean.metz/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import PurePath\n",
    "\n",
    "# add custom python modules root to the path variable,\n",
    "root_path = PurePath(os.getcwd()).parents[0]\n",
    "print(root_path)\n",
    "src_path = str(root_path.joinpath('src'))\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 98/422 [00:00<00:00, 972.97it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t5688.01\t0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 192/422 [00:00<00:00, 958.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t5462.72\t0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 191/422 [00:00<00:00, 947.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\t5411.01\t0.932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 187/422 [00:00<00:00, 916.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\t5195.46\t0.932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 188/422 [00:00<00:00, 936.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\t5142.77\t0.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 89/422 [00:00<00:00, 883.71it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\t4975.33\t0.933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 83/422 [00:00<00:00, 827.77it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\t4884.98\t0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 93/422 [00:00<00:00, 920.43it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\t4830.40\t0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 94/422 [00:00<00:00, 933.17it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\t4833.06\t0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\t4627.79\t0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from train import train_model\n",
    "from tqdm.notebook import tqdm\n",
    "train_model(((train_X, train_Y), (test_X, test_Y)), model, optimizer, n_iter, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
