{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagger \n",
    "\n",
    "This example shows the definition of a *tagger model* using simple `HashEmbed` and `Relu` layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinc.api import prefer_gpu\n",
    "prefer_gpu()\n",
    "\n",
    "from thinc.api import fix_random_seed\n",
    "fix_random_seed(0)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data, model, optimizer, n_iter, batch_size):\n",
    "    (train_X, train_y), (test_X, test_y) = data\n",
    "    model.initialize(X=train_X[:5], Y=train_y[:5])\n",
    "    for n in range(n_iter):\n",
    "        loss = 0.0\n",
    "        batches = model.ops.multibatch(batch_size, train_X, train_y, shuffle=True)\n",
    "        for X, Y in tqdm(batches, leave=False):\n",
    "            Yh, backprop = model.begin_update(X)\n",
    "            d_loss = []\n",
    "            for i in range(len(Yh)):\n",
    "                d_loss.append(Yh[i] - Y[i])\n",
    "                loss += ((Yh[i] - Y[i]) ** 2).sum()\n",
    "            backprop(d_loss)\n",
    "            model.finish_update(optimizer)\n",
    "        score = evaluate(model, test_X, test_y, batch_size)\n",
    "        print(f\"{n}\\t{loss:.2f}\\t{score:.3f}\")\n",
    "        \n",
    "def evaluate(model, test_X, test_Y, batch_size):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for X, Y in model.ops.multibatch(batch_size, test_X, test_Y):\n",
    "        Yh = model.predict(X)\n",
    "        for yh, y in zip(Yh, Y):\n",
    "            correct += (y.argmax(axis=1) == yh.argmax(axis=1)).sum()\n",
    "            total += y.shape[0]\n",
    "    return float(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinc.api import HashEmbed, Maxout, Softmax, expand_window, Relu\n",
    "from thinc.api import residual, strings2arrays, with_array, clone, chain, concatenate\n",
    "\n",
    "\n",
    "width = 32\n",
    "n_tags = 17\n",
    "vector_width = 16\n",
    "\n",
    "model = chain(\n",
    "    strings2arrays(),\n",
    "    with_array(\n",
    "        chain(\n",
    "            HashEmbed(width, vector_width, column=0),\n",
    "            expand_window(1),\n",
    "            Relu(nI=96, nO=width),\n",
    "            Relu(nI=width, nO=width),\n",
    "            Softmax(nI=width, nO=n_tags)\n",
    "        )\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_datasets\n",
    "\n",
    "\n",
    "CONFIG = \"\"\"\n",
    "[hyper_params]\n",
    "width = 32\n",
    "vector_width = 16\n",
    "learn_rate = 0.001\n",
    "\n",
    "[training]\n",
    "n_iter = 10\n",
    "batch_size = 128\n",
    "\n",
    "[optimizer]\n",
    "@optimizers = \"Adam.v1\"\n",
    "learn_rate = ${hyper_params:learn_rate}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from thinc.api import registry, Config\n",
    "\n",
    "config = Config().from_str(CONFIG)\n",
    "loaded_config = registry.make_from_config(config)\n",
    "\n",
    "optimizer = loaded_config[\"optimizer\"]\n",
    "n_iter = loaded_config[\"training\"][\"n_iter\"]\n",
    "batch_size = loaded_config[\"training\"][\"batch_size\"]\n",
    "\n",
    "(train_X, train_y), (test_X, test_y) = data = ml_datasets.ud_ancora_pos_tags()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 14/112 [00:00<00:00, 137.06it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t392983.74\t0.415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 13/112 [00:00<00:00, 126.88it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t300392.67\t0.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 13/112 [00:00<00:00, 120.35it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\t261122.23\t0.580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 12/112 [00:00<00:00, 117.04it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\t235691.01\t0.616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 12/112 [00:00<00:00, 113.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\t218414.26\t0.642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 13/112 [00:00<00:00, 125.38it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\t206413.16\t0.658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 11/112 [00:00<00:00, 107.75it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\t198596.01\t0.665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 12/112 [00:00<00:00, 117.51it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\t192651.78\t0.675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 12/112 [00:00<00:00, 117.24it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\t187864.93\t0.680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\t183994.92\t0.686\n"
     ]
    }
   ],
   "source": [
    "train_model(data, model, optimizer, n_iter, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thinc.ai] *",
   "language": "python",
   "name": "conda-env-thinc.ai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
