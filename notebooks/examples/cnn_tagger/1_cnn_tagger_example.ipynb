{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagger \n",
    "\n",
    "This example shows the definition of a *tagger model* using simple `HashEmbed` and `Relu` layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinc.api import prefer_gpu\n",
    "prefer_gpu()\n",
    "\n",
    "from thinc.api import fix_random_seed\n",
    "fix_random_seed(0)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data, model, optimizer, n_iter, batch_size):\n",
    "    (train_X, train_y), (test_X, test_y) = data\n",
    "    model.initialize(X=train_X[:5], Y=train_y[:5])\n",
    "    for n in range(n_iter):\n",
    "        loss = 0.0\n",
    "        batches = model.ops.multibatch(batch_size, train_X, train_y, shuffle=True)\n",
    "        for X, Y in tqdm(batches, leave=False):\n",
    "            Yh, backprop = model.begin_update(X)\n",
    "            d_loss = []\n",
    "            for i in range(len(Yh)):\n",
    "                d_loss.append(Yh[i] - Y[i])\n",
    "                loss += ((Yh[i] - Y[i]) ** 2).sum()\n",
    "            backprop(d_loss)\n",
    "            model.finish_update(optimizer)\n",
    "        score = evaluate(model, test_X, test_y, batch_size)\n",
    "        print(f\"{n}\\t{loss:.2f}\\t{score:.3f}\")\n",
    "        \n",
    "def evaluate(model, test_X, test_Y, batch_size):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for X, Y in model.ops.multibatch(batch_size, test_X, test_Y):\n",
    "        Yh = model.predict(X)\n",
    "        for yh, y in zip(Yh, Y):\n",
    "            correct += (y.argmax(axis=1) == yh.argmax(axis=1)).sum()\n",
    "            total += y.shape[0]\n",
    "    return float(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinc.api import HashEmbed, Maxout, Softmax, expand_window, Relu\n",
    "from thinc.api import residual, strings2arrays, with_array, clone, chain, concatenate\n",
    "\n",
    "\n",
    "width = 32\n",
    "n_tags = 17\n",
    "vector_width = 16\n",
    "\n",
    "model = chain(\n",
    "    strings2arrays(),\n",
    "    with_array(\n",
    "        chain(\n",
    "            HashEmbed(width, vector_width, column=0),\n",
    "            expand_window(1),\n",
    "            Relu(nI=96, nO=width),\n",
    "            Relu(nI=width, nO=width),\n",
    "            Softmax(nI=width, nO=n_tags)\n",
    "        )\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_datasets\n",
    "\n",
    "\n",
    "CONFIG = \"\"\"\n",
    "[hyper_params]\n",
    "width = 32\n",
    "vector_width = 16\n",
    "learn_rate = 0.001\n",
    "\n",
    "[training]\n",
    "n_iter = 10\n",
    "batch_size = 128\n",
    "\n",
    "[optimizer]\n",
    "@optimizers = \"Adam.v1\"\n",
    "learn_rate = ${hyper_params:learn_rate}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from thinc.api import registry, Config\n",
    "\n",
    "config = Config().from_str(CONFIG)\n",
    "loaded_config = registry.make_from_config(config)\n",
    "\n",
    "optimizer = loaded_config[\"optimizer\"]\n",
    "n_iter = loaded_config[\"training\"][\"n_iter\"]\n",
    "batch_size = loaded_config[\"training\"][\"batch_size\"]\n",
    "\n",
    "(train_X, train_y), (test_X, test_y) = data = ml_datasets.ud_ancora_pos_tags(limit=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 8/8 [00:00<00:00, 75.26it/s]0\t31413.33\t0.209\n100%|██████████| 8/8 [00:00<00:00, 77.47it/s]1\t31278.76\t0.188\n  0%|          | 0/8 [00:00<?, ?it/s]2\t30983.96\t0.201\n3\t30440.91\t0.181\n  0%|          | 0/8 [00:00<?, ?it/s]4\t29765.40\t0.180\n5\t29511.00\t0.180\n  0%|          | 0/8 [00:00<?, ?it/s]6\t29391.66\t0.180\n7\t29217.76\t0.180\n  0%|          | 0/8 [00:00<?, ?it/s]8\t28961.60\t0.243\n9\t28540.47\t0.371\n"
    }
   ],
   "source": [
    "model.initialize(X=train_X[:5], Y=train_y[:5])\n",
    "train_model(data, model, optimizer, n_iter, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('thinc.ai': conda)",
   "language": "python",
   "name": "python_defaultSpec_1600260606765"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}