{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagger \n",
    "\n",
    "This example shows the usage of operator overloading to define the same network architecture show in the example 2.\n",
    "\n",
    "Therefore, it works like this:\n",
    "\n",
    "* `MultiEmbed` layer: multiple numeric ID features are extracted for each word, and each feature is separately embedded. The separate vectors are concatenated and returned.\n",
    "\n",
    "* `Hidden`: the concatenated embeddings are passed through a dense layer with a “maxout” activation [Goodfellow et al, 2013](https://arxiv.org/abs/1302.4389).\n",
    "\n",
    "* `CNN layers`: several convolutional layers are applied in sequence for contextual encoding (`clone` function). Each CNN layer performs a “sequence-to-column” transformation, where a window of surrounding words is concatenated to each vector (`expand_window`). A `Hidden` layer then maps the result back to the original dimensionality. Residual connections and layer normalization are used to assist convergence (`residual` - a unary combinator creating a residual connection).\n",
    "\n",
    "* `Softmax`: gives the most likelly tag as the output of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinc.api import prefer_gpu\n",
    "prefer_gpu()\n",
    "\n",
    "from thinc.api import fix_random_seed\n",
    "fix_random_seed(0)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data, model, optimizer, n_iter, batch_size):\n",
    "    (train_X, train_y), (test_X, test_y) = data\n",
    "    model.initialize(X=train_X[:5], Y=train_y[:5])\n",
    "    for n in range(n_iter):\n",
    "        loss = 0.0\n",
    "        batches = model.ops.multibatch(batch_size, train_X, train_y, shuffle=True)\n",
    "        for X, Y in tqdm(batches, leave=False):\n",
    "            Yh, backprop = model.begin_update(X)\n",
    "            d_loss = []\n",
    "            for i in range(len(Yh)):\n",
    "                d_loss.append(Yh[i] - Y[i])\n",
    "                loss += ((Yh[i] - Y[i]) ** 2).sum()\n",
    "            backprop(d_loss)\n",
    "            model.finish_update(optimizer)\n",
    "        score = evaluate(model, test_X, test_y, batch_size)\n",
    "        print(f\"{n}\\t{loss:.2f}\\t{score:.3f}\")\n",
    "        \n",
    "def evaluate(model, test_X, test_Y, batch_size):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for X, Y in model.ops.multibatch(batch_size, test_X, test_Y):\n",
    "        Yh = model.predict(X)\n",
    "        for yh, y in zip(Yh, Y):\n",
    "            correct += (y.argmax(axis=1) == yh.argmax(axis=1)).sum()\n",
    "            total += y.shape[0]\n",
    "    return float(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinc.api import Model, HashEmbed, Maxout, Softmax, expand_window, Relu\n",
    "from thinc.api import residual, strings2arrays, with_array, clone, chain, concatenate\n",
    "\n",
    "\n",
    "width = 128\n",
    "depth = 4\n",
    "n_tags = 17\n",
    "\n",
    "\n",
    "def Hidden(nO, dropout=0.2):\n",
    "     return Maxout(nO, nP=3, normalize=True, dropout=dropout)\n",
    "\n",
    "def CNN(width):\n",
    "    return residual(chain(expand_window(1), Hidden(width)))\n",
    "\n",
    "\n",
    "with Model.define_operators({\">>\": chain, \"**\": clone, \"|\": concatenate}):\n",
    "    model = strings2arrays() >> with_array(\n",
    "                (\n",
    "                    HashEmbed(width, 4000, column=0)\n",
    "                    | HashEmbed(width // 2, 2000, column=0)\n",
    "                    | HashEmbed(width // 2, 2000, column=0)\n",
    "                    | HashEmbed(width // 2, 2000, column=0)                \n",
    "                )\n",
    "                >> Hidden(width)\n",
    "                >> clone(CNN(width), depth)\n",
    "                >> Softmax(n_tags)\n",
    "        )\n",
    "\n",
    "# model.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_datasets\n",
    "\n",
    "\n",
    "CONFIG = \"\"\"\n",
    "[hyper_params]\n",
    "width = 32\n",
    "vector_width = 16\n",
    "learn_rate = 0.001\n",
    "\n",
    "[training]\n",
    "n_iter = 10\n",
    "batch_size = 128\n",
    "\n",
    "[optimizer]\n",
    "@optimizers = \"Adam.v1\"\n",
    "learn_rate = ${hyper_params:learn_rate}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from thinc.api import registry, Config\n",
    "\n",
    "config = Config().from_str(CONFIG)\n",
    "loaded_config = registry.make_from_config(config)\n",
    "\n",
    "optimizer = loaded_config[\"optimizer\"]\n",
    "n_iter = loaded_config[\"training\"][\"n_iter\"]\n",
    "batch_size = loaded_config[\"training\"][\"batch_size\"]\n",
    "\n",
    "(train_X, train_y), (test_X, test_y) = data = ml_datasets.ud_ancora_pos_tags(limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "0%|          | 0/8 [00:00<?, ?it/s]0\t28959.23\t0.585\n  0%|          | 0/8 [00:00<?, ?it/s]1\t16876.99\t0.703\n  0%|          | 0/8 [00:00<?, ?it/s]2\t11079.14\t0.776\n  0%|          | 0/8 [00:00<?, ?it/s]3\t7632.26\t0.818\n  0%|          | 0/8 [00:00<?, ?it/s]4\t5030.11\t0.841\n  0%|          | 0/8 [00:00<?, ?it/s]5\t3160.11\t0.851\n  0%|          | 0/8 [00:00<?, ?it/s]6\t1869.66\t0.859\n  0%|          | 0/8 [00:00<?, ?it/s]7\t1112.38\t0.862\n  0%|          | 0/8 [00:00<?, ?it/s]8\t724.43\t0.863\n100%|██████████| 8/8 [00:02<00:00,  3.21it/s]9\t521.95\t0.864\n"
    }
   ],
   "source": [
    "train_model(data, model, optimizer, n_iter, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('thinc.ai': conda)",
   "language": "python",
   "name": "python_defaultSpec_1600261107249"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}