{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagger \n",
    "\n",
    "This example shows the definition of a *tagger model* with a _multi-feature CNN token-to-vector encoder_.\n",
    "\n",
    "It works like this:\n",
    "\n",
    "* `MultiEmbed` layer: multiple numeric ID features are extracted for each word, and each feature is separately embedded. The separate vectors are concatenated and returned.\n",
    "\n",
    "* `Hidden`: the concatenated embeddings are passed through a dense layer with a “maxout” activation [Goodfellow et al, 2013](https://arxiv.org/abs/1302.4389).\n",
    "\n",
    "* `CNN layers`: several convolutional layers are applied in sequence for contextual encoding (`clone` function). Each CNN layer performs a “sequence-to-column” transformation, where a window of surrounding words is concatenated to each vector (`expand_window`). A `Hidden` layer then maps the result back to the original dimensionality. Residual connections and layer normalization are used to assist convergence (`residual` - a unary combinator creating a residual connection).\n",
    "\n",
    "* `Softmax`: gives the most likelly tag as the output of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinc.api import prefer_gpu\n",
    "prefer_gpu()\n",
    "\n",
    "from thinc.api import fix_random_seed\n",
    "fix_random_seed(0)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data, model, optimizer, n_iter, batch_size):\n",
    "    (train_X, train_y), (test_X, test_y) = data\n",
    "    model.initialize(X=train_X[:5], Y=train_y[:5])\n",
    "    for n in range(n_iter):\n",
    "        loss = 0.0\n",
    "        batches = model.ops.multibatch(batch_size, train_X, train_y, shuffle=True)\n",
    "        for X, Y in tqdm(batches, leave=False):\n",
    "            Yh, backprop = model.begin_update(X)\n",
    "            d_loss = []\n",
    "            for i in range(len(Yh)):\n",
    "                d_loss.append(Yh[i] - Y[i])\n",
    "                loss += ((Yh[i] - Y[i]) ** 2).sum()\n",
    "            backprop(d_loss)\n",
    "            model.finish_update(optimizer)\n",
    "        score = evaluate(model, test_X, test_y, batch_size)\n",
    "        print(f\"{n}\\t{loss:.2f}\\t{score:.3f}\")\n",
    "        \n",
    "def evaluate(model, test_X, test_Y, batch_size):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for X, Y in model.ops.multibatch(batch_size, test_X, test_Y):\n",
    "        Yh = model.predict(X)\n",
    "        for yh, y in zip(Yh, Y):\n",
    "            correct += (y.argmax(axis=1) == yh.argmax(axis=1)).sum()\n",
    "            total += y.shape[0]\n",
    "    return float(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinc.api import HashEmbed, Maxout, Softmax, expand_window, Relu\n",
    "from thinc.api import residual, strings2arrays, with_array, clone, chain, concatenate\n",
    "\n",
    "width = 128\n",
    "depth = 4\n",
    "n_tags = 17\n",
    "\n",
    "def MultiEmbed(width):\n",
    "    return concatenate(\n",
    "        HashEmbed(width, 4000, column=0),\n",
    "        HashEmbed(width // 2, 2000, column=0),\n",
    "        HashEmbed(width // 2, 2000, column=0),\n",
    "        HashEmbed(width // 2, 2000, column=0),\n",
    "    )\n",
    "\n",
    "def Hidden(nO, dropout=0.2):\n",
    "     return Maxout(nO, nP=3, normalize=True, dropout=dropout)\n",
    "\n",
    "def CNN(width):\n",
    "    return residual(chain(expand_window(1), Hidden(width)))\n",
    "\n",
    "model = chain(\n",
    "    strings2arrays(),\n",
    "    with_array(\n",
    "        chain(\n",
    "            MultiEmbed(width),\n",
    "            Hidden(width),\n",
    "            clone(CNN(width), depth),\n",
    "            Softmax(n_tags)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# model.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_datasets\n",
    "\n",
    "\n",
    "CONFIG = \"\"\"\n",
    "[hyper_params]\n",
    "width = 32\n",
    "vector_width = 16\n",
    "learn_rate = 0.001\n",
    "\n",
    "[training]\n",
    "n_iter = 10\n",
    "batch_size = 128\n",
    "\n",
    "[optimizer]\n",
    "@optimizers = \"Adam.v1\"\n",
    "learn_rate = ${hyper_params:learn_rate}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from thinc.api import registry, Config\n",
    "\n",
    "config = Config().from_str(CONFIG)\n",
    "loaded_config = registry.make_from_config(config)\n",
    "\n",
    "optimizer = loaded_config[\"optimizer\"]\n",
    "n_iter = loaded_config[\"training\"][\"n_iter\"]\n",
    "batch_size = loaded_config[\"training\"][\"batch_size\"]\n",
    "\n",
    "(train_X, train_y), (test_X, test_y) = data = ml_datasets.ud_ancora_pos_tags()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/112 [00:00<?, ?it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t111415.20\t0.922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/112 [00:00<?, ?it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t35114.85\t0.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/112 [00:00<?, ?it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\t22464.63\t0.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/112 [00:00<?, ?it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\t16577.96\t0.949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/112 [00:00<?, ?it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\t13216.76\t0.949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/112 [00:00<?, ?it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\t11125.42\t0.951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/112 [00:00<?, ?it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\t9697.56\t0.951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/112 [00:00<?, ?it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\t8598.47\t0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/112 [00:00<?, ?it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\t7719.94\t0.951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\t7155.96\t0.950\n"
     ]
    }
   ],
   "source": [
    "train_model(data, model, optimizer, n_iter, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thinc.ai] *",
   "language": "python",
   "name": "conda-env-thinc.ai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
