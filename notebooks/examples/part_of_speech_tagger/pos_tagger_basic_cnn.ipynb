{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Requirement already satisfied: thinc>=8.0.0a0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (8.0.0a1)\r\n",
      "Collecting ml_datasets\r\n",
      "  Using cached ml_datasets-0.1.6.tar.gz (8.0 kB)\r\n",
      "Requirement already satisfied: tqdm>=4.41 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (4.46.0)\r\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4.1; python_version < \"3.8\" in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (3.7.4.1)\r\n",
      "Requirement already satisfied: numpy>=1.7.0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (1.18.1)\r\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (0.6.0)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.0.0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (2.0.1)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (1.0.2)\r\n",
      "Requirement already satisfied: setuptools in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (46.4.0.post20200518)\r\n",
      "Requirement already satisfied: catalogue<3.0.0,>=0.2.0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (2.0.0)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (2.0.3)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (3.0.2)\r\n",
      "Requirement already satisfied: pydantic<2.0.0,>=1.4.0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (1.5.1)\r\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from catalogue<3.0.0,>=0.2.0->thinc>=8.0.0a0) (1.6.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<3.0.0,>=0.2.0->thinc>=8.0.0a0) (2.2.0)\r\n",
      "Building wheels for collected packages: ml-datasets\r\n",
      "  Building wheel for ml-datasets (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for ml-datasets: filename=ml_datasets-0.1.6-py3-none-any.whl size=11254 sha256=d5c509d212646b11ebebb0f15e75780c6638419ad7cba122b6a473e8e9e11023\r\n",
      "  Stored in directory: /Users/jean.metz/Library/Caches/pip/wheels/34/ac/d7/5df981dd308bb698a0dab0e0c87321fa7d2863c867d9a852f5\r\n",
      "Successfully built ml-datasets\r\n",
      "Installing collected packages: ml-datasets\r\n",
      "Successfully installed ml-datasets-0.1.6\r\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "!pip install \"thinc>=8.0.0a0\" ml_datasets \"tqdm>=4.41\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "from thinc.api import prefer_gpu\n",
    "prefer_gpu()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import ml_datasets\n",
    "from tqdm.notebook import tqdm\n",
    "from thinc.api import fix_random_seed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e1f5f87e8014>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfix_random_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdev_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mml_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mud_ancora_pos_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fix_random_seed' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'fix_random_seed' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "fix_random_seed(0)\n",
    "\n",
    "def train_model(model, optimizer, n_iter, batch_size):\n",
    "    (train_X, train_y), (dev_X, dev_y) = ml_datasets.ud_ancora_pos_tags()\n",
    "    model.initialize(X=train_X[:5], Y=train_y[:5])\n",
    "    for n in range(n_iter):\n",
    "        loss = 0.0\n",
    "        batches = model.ops.multibatch(batch_size, train_X, train_y, shuffle=True)\n",
    "        for X, Y in tqdm(batches, leave=False):\n",
    "            Yh, backprop = model.begin_update(X)\n",
    "            d_loss = []\n",
    "            for i in range(len(Yh)):\n",
    "                d_loss.append(Yh[i] - Y[i])\n",
    "                loss += ((Yh[i] - Y[i]) ** 2).sum()\n",
    "            backprop(d_loss)\n",
    "            model.finish_update(optimizer)\n",
    "        score = evaluate(model, dev_X, dev_y, batch_size)\n",
    "        print(f\"{n}\\t{loss:.2f}\\t{score:.3f}\")\n",
    "        \n",
    "def evaluate(model, dev_X, dev_Y, batch_size):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for X, Y in model.ops.multibatch(batch_size, dev_X, dev_Y):\n",
    "        Yh = model.predict(X)\n",
    "        for yh, y in zip(Yh, Y):\n",
    "            correct += (y.argmax(axis=1) == yh.argmax(axis=1)).sum()\n",
    "            total += y.shape[0]\n",
    "    return float(correct / total)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Composing the model in code\n",
    "\n",
    "Here's the model definition, using the `>>` operator for the `chain` combinator.\n",
    "The `strings2arrays` transform converts a sequence of strings to a list of arrays. `with_array` \n",
    "transforms sequences (the sequences of arrays) into a contiguous 2-dimensional array on the way into \n",
    "and out of the model it wraps. This means our model has the following signature: \n",
    "`Model[Sequence[str], Sequence[Array2d]]`.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from thinc.api import Model, chain, strings2arrays, with_array, HashEmbed, expand_window, Relu, Softmax, Adam, warmup_linear\n",
    "\n",
    "width = 32\n",
    "vector_width = 16\n",
    "nr_classes = 17\n",
    "learn_rate = 0.001\n",
    "n_iter = 10\n",
    "batch_size = 128\n",
    "\n",
    "with Model.define_operators({\">>\": chain}):\n",
    "    model = strings2arrays() >> with_array(\n",
    "        HashEmbed(nO=width, nV=vector_width, column=0)\n",
    "        >> expand_window(window_size=1)\n",
    "        >> Relu(nO=width, nI=width * 3)\n",
    "        >> Relu(nO=width, nI=width)\n",
    "        >> Softmax(nO=nr_classes, nI=width)\n",
    "    )\n",
    "optimizer = Adam(learn_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Composing the model via config file\n",
    "\n",
    "If we want to rebuild the model defined above in a config file, we first need to break down its structure:\n",
    "\n",
    "* `chain` (any number of positional arguments)\n",
    "  * `strings2arrays` (no arguments)\n",
    "  * `with_array` (one argument **layer**)\n",
    "    * **layer:** `chain` (any number of positional arguments)\n",
    "      * `HashEmbed`\n",
    "      * `expand_window`\n",
    "      * `Relu`\n",
    "      * `Relu`\n",
    "      * `Softmax`\n",
    "\n",
    "`chain` takes a variable number of positional arguments (the layers to compose). \n",
    "In the config, positional arguments can be expressed using `*` in the dot notation. For example, \n",
    "`model.layer` could describe a function passed to `model` as the argument `layer`, while `model.*.relu` \n",
    "defines a positional argument passed to `model`. The name of the argument, e.g. `relu` – doesn't matter \n",
    "in this case. It just needs to be unique.\n",
    "\n",
    "> ⚠️ **Important note:** It is recommended to use a hybrid approach: wrap the model definition in a registered function\n",
    "> and configure it via the config."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CONFIG = \"\"\"\n",
    "[hyper_params]\n",
    "width = 32\n",
    "vector_width = 16\n",
    "learn_rate = 0.001\n",
    "\n",
    "[training]\n",
    "n_iter = 10\n",
    "batch_size = 128\n",
    "\n",
    "[model]\n",
    "@layers = \"chain.v1\"\n",
    "\n",
    "[model.*.strings2arrays]\n",
    "@layers = \"strings2arrays.v1\"\n",
    "\n",
    "[model.*.with_array]\n",
    "@layers = \"with_array.v1\"\n",
    "\n",
    "[model.*.with_array.layer]\n",
    "@layers = \"chain.v1\"\n",
    "\n",
    "[model.*.with_array.layer.*.hashembed]\n",
    "@layers = \"HashEmbed.v1\"\n",
    "nO = ${hyper_params:width}\n",
    "nV = ${hyper_params:vector_width}\n",
    "column = 0\n",
    "\n",
    "[model.*.with_array.layer.*.expand_window]\n",
    "@layers = \"expand_window.v1\"\n",
    "window_size = 1\n",
    "\n",
    "[model.*.with_array.layer.*.relu1]\n",
    "@layers = \"Relu.v1\"\n",
    "nO = ${hyper_params:width}\n",
    "nI = 96\n",
    "\n",
    "[model.*.with_array.layer.*.relu2]\n",
    "@layers = \"Relu.v1\"\n",
    "nO = ${hyper_params:width}\n",
    "nI = ${hyper_params:width}\n",
    "\n",
    "[model.*.with_array.layer.*.softmax]\n",
    "@layers = \"Softmax.v1\"\n",
    "nO = 17\n",
    "nI = ${hyper_params:width}\n",
    "\n",
    "[optimizer]\n",
    "@optimizers = \"Adam.v1\"\n",
    "learn_rate = ${hyper_params:learn_rate}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from thinc.api import registry, Config\n",
    "\n",
    "config = Config().from_str(CONFIG)\n",
    "loaded_config = registry.make_from_config(config)\n",
    "\n",
    "model = loaded_config[\"model\"]\n",
    "optimizer = loaded_config[\"optimizer\"]\n",
    "n_iter = loaded_config[\"training\"][\"n_iter\"]\n",
    "batch_size = loaded_config[\"training\"][\"batch_size\"]\n",
    "train_model(model, optimizer, n_iter, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Composing the model with code and config\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import thinc\n",
    "from thinc.api import Model, chain, strings2arrays, with_array, HashEmbed, expand_window, Relu, Softmax,\\\n",
    "    Adam, warmup_linear\n",
    "\n",
    "@thinc.registry.layers(\"cnn_tagger.v1\")\n",
    "def create_cnn_tagger(width: int, vector_width: int, nr_classes: int = 17) -> Model:\n",
    "    with Model.define_operators({\">>\": chain}):\n",
    "        model = strings2arrays() >> with_array(\n",
    "            HashEmbed(nO=width, nV=vector_width, column=0)\n",
    "            >> expand_window(window_size=1)\n",
    "            >> Relu(nO=width, nI=width * 3)\n",
    "            >> Relu(nO=width, nI=width)\n",
    "            >> Softmax(nO=nr_classes, nI=width)\n",
    "        )\n",
    "    return model\n",
    "\n",
    "CONFIG = \"\"\"\n",
    "[hyper_params]\n",
    "width = 32\n",
    "vector_width = 16\n",
    "learn_rate = 0.001\n",
    "\n",
    "[training]\n",
    "n_iter = 10\n",
    "batch_size = 128\n",
    "\n",
    "[model]\n",
    "@layers = \"cnn_tagger.v1\"\n",
    "width = ${hyper_params:width}\n",
    "vector_width = ${hyper_params:vector_width}\n",
    "nr_classes = 17\n",
    "\n",
    "[optimizer]\n",
    "@optimizers = \"Adam.v1\"\n",
    "learn_rate = ${hyper_params:learn_rate}\n",
    "\"\"\"\n",
    "\n",
    "loaded_config = registry.make_from_config(Config().from_str(CONFIG))\n",
    "\n",
    "model = loaded_config[\"model\"]\n",
    "optimizer = loaded_config[\"optimizer\"]\n",
    "n_iter = loaded_config[\"training\"][\"n_iter\"]\n",
    "batch_size = loaded_config[\"training\"][\"batch_size\"]\n",
    "train_model(model, optimizer, n_iter, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}