{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Requirement already satisfied: thinc>=8.0.0a0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (8.0.0a1)\nRequirement already satisfied: ml_datasets in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (0.1.6)\nRequirement already satisfied: tqdm>=4.41 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (4.47.0)\nRequirement already satisfied: pydantic<2.0.0,>=1.4.0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (1.5.1)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (3.0.2)\nRequirement already satisfied: numpy>=1.7.0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (1.18.1)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (2.0.3)\nRequirement already satisfied: setuptools in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (47.1.1.post20200604)\nRequirement already satisfied: catalogue<3.0.0,>=0.2.0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (2.0.0)\nRequirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (0.6.0)\nRequirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4.1; python_version < \"3.8\" in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (3.7.4.1)\nRequirement already satisfied: srsly<3.0.0,>=2.0.0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (2.0.1)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from thinc>=8.0.0a0) (1.0.2)\nRequirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from catalogue<3.0.0,>=0.2.0->thinc>=8.0.0a0) (1.6.0)\nRequirement already satisfied: zipp>=0.5 in /Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<3.0.0,>=0.2.0->thinc>=8.0.0a0) (3.1.0)\n"
    }
   ],
   "source": [
    "!pip install \"thinc>=8.0.0a0\" ml_datasets \"tqdm>=4.41\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "False"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "from thinc.api import prefer_gpu\n",
    "prefer_gpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import ml_datasets\n",
    "from tqdm import tqdm\n",
    "from thinc.api import fix_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fix_random_seed(0)\n",
    "\n",
    "def train_model(data, model, optimizer, n_iter, batch_size):\n",
    "    (train_X, train_y), (test_X, test_y) = data\n",
    "    model.initialize(X=train_X[:5], Y=train_y[:5])\n",
    "    for n in range(n_iter):\n",
    "        loss = 0.0\n",
    "        batches = model.ops.multibatch(batch_size, train_X, train_y, shuffle=True)\n",
    "        for X, Y in tqdm(batches, leave=False):\n",
    "            Yh, backprop = model.begin_update(X)\n",
    "            d_loss = []\n",
    "            for i in range(len(Yh)):\n",
    "                d_loss.append(Yh[i] - Y[i])\n",
    "                loss += ((Yh[i] - Y[i]) ** 2).sum()\n",
    "            backprop(d_loss)\n",
    "            model.finish_update(optimizer)\n",
    "        score = evaluate(model, test_X, test_y, batch_size)\n",
    "        print(f\"{n}\\t{loss:.2f}\\t{score:.3f}\")\n",
    "        \n",
    "def evaluate(model, test_X, test_Y, batch_size):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for X, Y in model.ops.multibatch(batch_size, test_X, test_Y):\n",
    "        Yh = model.predict(X)\n",
    "        for yh, y in zip(Yh, Y):\n",
    "            correct += (y.argmax(axis=1) == yh.argmax(axis=1)).sum()\n",
    "            total += y.shape[0]\n",
    "    return float(correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Composing the model in code\n",
    "\n",
    "Here's the model definition, using the `>>` operator for the `chain` combinator.\n",
    "The `strings2arrays` transform converts a sequence of strings to a list of arrays. `with_array` \n",
    "transforms sequences (the sequences of arrays) into a contiguous 2-dimensional array on the way into \n",
    "and out of the model it wraps. This means our model has the following signature: \n",
    "`Model[Sequence[str], Sequence[Array2d]]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "from thinc.api import Model, chain, strings2arrays, with_array, HashEmbed, expand_window, Relu, Softmax, Adam, warmup_linear\n",
    "\n",
    "width = 32\n",
    "vector_width = 16\n",
    "nr_classes = 17\n",
    "learn_rate = 0.001\n",
    "n_iter = 10\n",
    "batch_size = 128\n",
    "\n",
    "with Model.define_operators({\">>\": chain}):\n",
    "    model = strings2arrays() >> with_array(\n",
    "        HashEmbed(nO=width, nV=vector_width, column=0)\n",
    "        >> expand_window(window_size=1) # 1-step Convolution\n",
    "        >> Relu(nO=width, nI=width * 3)\n",
    "        >> Relu(nO=width, nI=width)\n",
    "        >> Softmax(nO=nr_classes, nI=width)\n",
    "    )\n",
    "optimizer = Adam(learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composing the model via config file\n",
    "\n",
    "If we want to rebuild the model defined above in a config file, we first need to break down its structure:\n",
    "\n",
    "* `chain` (any number of positional arguments)\n",
    "  * `strings2arrays` (no arguments)\n",
    "  * `with_array` (one argument **layer**)\n",
    "    * **layer:** `chain` (any number of positional arguments)\n",
    "      * `HashEmbed`\n",
    "      * `expand_window`\n",
    "      * `Relu`\n",
    "      * `Relu`\n",
    "      * `Softmax`\n",
    "\n",
    "`chain` takes a variable number of positional arguments (the layers to compose). \n",
    "In the config, positional arguments can be expressed using `*` in the dot notation. For example, \n",
    "`model.layer` could describe a function passed to `model` as the argument `layer`, while `model.*.relu` \n",
    "defines a positional argument passed to `model`. The name of the argument, e.g. `relu` – doesn't matter \n",
    "in this case. It just needs to be unique.\n",
    "\n",
    "> ⚠️ **Important note:** It is recommended to use a hybrid approach: wrap the model definition in a registered function\n",
    "> and configure it via the config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "CONFIG = \"\"\"\n",
    "[hyper_params]\n",
    "width = 32\n",
    "vector_width = 16\n",
    "learn_rate = 0.001\n",
    "n_tags = 17\n",
    "\n",
    "[training]\n",
    "n_iter = 10\n",
    "batch_size = 128\n",
    "\n",
    "[model]\n",
    "@layers = \"chain.v1\"\n",
    "\n",
    "[model.*.strings2arrays]\n",
    "@layers = \"strings2arrays.v1\"\n",
    "\n",
    "[model.*.with_array]\n",
    "@layers = \"with_array.v1\"\n",
    "\n",
    "[model.*.with_array.layer]\n",
    "@layers = \"chain.v1\"\n",
    "\n",
    "[model.*.with_array.layer.*.hashembed]\n",
    "@layers = \"HashEmbed.v1\"\n",
    "nO = ${hyper_params:width}\n",
    "nV = ${hyper_params:vector_width}\n",
    "column = 0\n",
    "\n",
    "[model.*.with_array.layer.*.expand_window]\n",
    "@layers = \"expand_window.v1\"\n",
    "window_size = 1\n",
    "\n",
    "[model.*.with_array.layer.*.relu1]\n",
    "@layers = \"Relu.v1\"\n",
    "nO = ${hyper_params:width}\n",
    "nI = 96\n",
    "\n",
    "[model.*.with_array.layer.*.relu2]\n",
    "@layers = \"Relu.v1\"\n",
    "nO = ${hyper_params:width}\n",
    "nI = ${hyper_params:width}\n",
    "\n",
    "[model.*.with_array.layer.*.softmax]\n",
    "@layers = \"Softmax.v1\"\n",
    "nO = ${hyper_params:n_tags}\n",
    "nI = ${hyper_params:width}\n",
    "\n",
    "[optimizer]\n",
    "@optimizers = \"Adam.v1\"\n",
    "learn_rate = ${hyper_params:learn_rate}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from thinc.api import registry, Config\n",
    "\n",
    "config = Config().from_str(CONFIG)\n",
    "loaded_config = registry.make_from_config(config)\n",
    "\n",
    "model = loaded_config[\"model\"]\n",
    "optimizer = loaded_config[\"optimizer\"]\n",
    "n_iter = loaded_config[\"training\"][\"n_iter\"]\n",
    "batch_size = loaded_config[\"training\"][\"batch_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "8%|▊         | 9/112 [00:00<00:01, 86.79it/s]0\t397584.09\t0.373\n  8%|▊         | 9/112 [00:00<00:01, 83.08it/s]1\t307524.31\t0.538\n  8%|▊         | 9/112 [00:00<00:01, 83.08it/s]2\t260264.22\t0.584\n  7%|▋         | 8/112 [00:00<00:01, 79.92it/s]3\t239829.69\t0.613\n  8%|▊         | 9/112 [00:00<00:01, 82.13it/s]4\t224328.70\t0.627\n  8%|▊         | 9/112 [00:00<00:01, 84.93it/s]5\t212690.89\t0.644\n  8%|▊         | 9/112 [00:00<00:01, 80.85it/s]6\t203882.17\t0.657\n  8%|▊         | 9/112 [00:00<00:01, 85.27it/s]7\t197021.96\t0.668\n  8%|▊         | 9/112 [00:00<00:01, 81.19it/s]8\t191324.42\t0.678\n 95%|█████████▍| 106/112 [00:01<00:00, 83.61it/s]9\t186663.51\t0.684\n"
    }
   ],
   "source": [
    "data = ml_datasets.ud_ancora_pos_tags()\n",
    "train_model(data, model, optimizer, n_iter, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composing the model with code and config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "7%|▋         | 8/112 [00:00<00:01, 77.85it/s]0\t394804.24\t0.445\n  8%|▊         | 9/112 [00:00<00:01, 81.89it/s]1\t281690.39\t0.552\n  8%|▊         | 9/112 [00:00<00:01, 79.89it/s]2\t251534.66\t0.578\n  8%|▊         | 9/112 [00:00<00:01, 83.73it/s]3\t233599.77\t0.607\n  8%|▊         | 9/112 [00:00<00:01, 86.54it/s]4\t220240.38\t0.630\n  8%|▊         | 9/112 [00:00<00:01, 83.18it/s]5\t209728.11\t0.645\n  8%|▊         | 9/112 [00:00<00:01, 85.49it/s]6\t201995.64\t0.658\n  8%|▊         | 9/112 [00:00<00:01, 78.35it/s]7\t196320.43\t0.668\n  8%|▊         | 9/112 [00:00<00:01, 83.07it/s]8\t191455.18\t0.675\n 97%|█████████▋| 109/112 [00:01<00:00, 86.97it/s]9\t187216.77\t0.685\n"
    }
   ],
   "source": [
    "import thinc\n",
    "from thinc.api import Model, chain, strings2arrays, with_array, HashEmbed, expand_window, Relu, Softmax,\\\n",
    "    Adam, warmup_linear\n",
    "\n",
    "@thinc.registry.layers(\"cnn_tagger.v1\")\n",
    "def create_cnn_tagger(width: int, vector_width: int, nr_classes: int = 17) -> Model:\n",
    "    with Model.define_operators({\">>\": chain}):\n",
    "        model = strings2arrays() >> with_array(\n",
    "            HashEmbed(nO=width, nV=vector_width, column=0)\n",
    "            >> expand_window(window_size=1)\n",
    "            >> Relu(nO=width, nI=width * 3)\n",
    "            >> Relu(nO=width, nI=width)\n",
    "            >> Softmax(nO=nr_classes, nI=width)\n",
    "        )\n",
    "    return model\n",
    "\n",
    "CONFIG = \"\"\"\n",
    "[hyper_params]\n",
    "width = 32\n",
    "vector_width = 16\n",
    "learn_rate = 0.001\n",
    "\n",
    "[training]\n",
    "n_iter = 10\n",
    "batch_size = 128\n",
    "\n",
    "[model]\n",
    "@layers = \"cnn_tagger.v1\"\n",
    "width = ${hyper_params:width}\n",
    "vector_width = ${hyper_params:vector_width}\n",
    "nr_classes = 17\n",
    "\n",
    "[optimizer]\n",
    "@optimizers = \"Adam.v1\"\n",
    "learn_rate = ${hyper_params:learn_rate}\n",
    "\"\"\"\n",
    "\n",
    "loaded_config = registry.make_from_config(Config().from_str(CONFIG))\n",
    "\n",
    "model = loaded_config[\"model\"]\n",
    "optimizer = loaded_config[\"optimizer\"]\n",
    "n_iter = loaded_config[\"training\"][\"n_iter\"]\n",
    "batch_size = loaded_config[\"training\"][\"batch_size\"]\n",
    "\n",
    "data = ml_datasets.ud_ancora_pos_tags()\n",
    "\n",
    "train_model(data, model, optimizer, n_iter, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}