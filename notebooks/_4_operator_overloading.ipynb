{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operator overloading for more concise model definitions\n",
    "\n",
    "Thinc allows you to **overload operators** and bind arbitrary functions to Python operators like `+`, `*`, but also `>>` or `@`. The `Model.define_operators` contextmanager takes a dict of operators mapped to functions – typically combinators like `chain`. The operators are only valid for the `with` block. This lets us define the model like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"thinc>=8.0.0a0\" ml_datasets \"tqdm>=4.41\" syntok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "False"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "from thinc.api import prefer_gpu\n",
    "prefer_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of defining the `chain` as a comma-separated list of elements, one can use custom operators.\n",
    "For example, transforming the following code \n",
    "\n",
    "```python\n",
    "from thinc.api import Model, chain, Relu, Softmax\n",
    "n_hidden = 32\n",
    "dropout = 0.2\n",
    "\n",
    "model = chain(\n",
    "    Relu(nO=n_hidden, dropout=dropout), \n",
    "    Relu(nO=n_hidden, dropout=dropout), \n",
    "    Softmax()\n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "into this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/Users/jean.metz/workspace/jmetzz/sandbox-thinc.ai\n['/Users/jean.metz/workspace/jmetzz/sandbox-thinc.ai/src', '/Users/jean.metz/workspace/jmetzz/sandbox-thinc.ai/notebooks', '/private/var/folders/b0/wtsjtzcx3mdb4z2kbs_2bxd1c3lb67/T/b482e531-dfb3-4077-b15e-7b7fd9fb4869', '/Users/jean.metz/miniconda/envs/thinc.ai/lib/python37.zip', '/Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7', '/Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/lib-dynload', '', '/Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages', '/Users/jean.metz/miniconda/envs/thinc.ai/lib/python3.7/site-packages/IPython/extensions', '/Users/jean.metz/.ipython']\n"
    }
   ],
   "source": [
    "# First, add src to sys.path\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import PurePath\n",
    "\n",
    "# add custom python modules root to the path variable,\n",
    "root_path = PurePath(os.getcwd()).parents[0]\n",
    "print(root_path)\n",
    "src_path = str(\n",
    "    root_path.joinpath('src'))\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "print(sys.path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinc.api import Model, chain, Relu, Softmax\n",
    "\n",
    " \n",
    "n_hidden = 32\n",
    "dropout = 0.2\n",
    "\n",
    "with Model.define_operators({\">>\": chain}):\n",
    "    model = Relu(nO=n_hidden, dropout=dropout) >> Relu(nO=n_hidden, dropout=dropout) >> Softmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now use the `model` object as an argument to the `train_model` function defined below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "18%|█▊        | 75/422 [00:00<00:00, 749.51it/s]Measuring performance across iterations:\n 23%|██▎       | 96/422 [00:00<00:00, 958.40it/s]0\t22486.57\t0.845\n 20%|██        | 86/422 [00:00<00:00, 854.79it/s]1\t10951.25\t0.890\n 22%|██▏       | 93/422 [00:00<00:00, 919.01it/s]2\t8775.06\t0.896\n 21%|██▏       | 90/422 [00:00<00:00, 897.51it/s]3\t7903.34\t0.909\n 21%|██▏       | 90/422 [00:00<00:00, 893.95it/s]4\t7232.81\t0.915\n 22%|██▏       | 91/422 [00:00<00:00, 901.38it/s]5\t6666.07\t0.918\n 21%|██        | 89/422 [00:00<00:00, 883.01it/s]6\t6439.15\t0.918\n 21%|██        | 87/422 [00:00<00:00, 861.36it/s]7\t6108.11\t0.924\n 21%|██        | 88/422 [00:00<00:00, 873.26it/s]8\t5841.27\t0.929\n 21%|██        | 89/422 [00:00<00:00, 883.25it/s]9\t5656.59\t0.928\n 40%|███▉      | 168/422 [00:00<00:00, 825.47it/s]10\t5528.26\t0.927\n 42%|████▏     | 176/422 [00:00<00:00, 873.26it/s]11\t5399.24\t0.931\n 20%|█▉        | 83/422 [00:00<00:00, 829.31it/s]12\t5204.12\t0.931\n 41%|████      | 173/422 [00:00<00:00, 862.12it/s]13\t5127.30\t0.934\n 42%|████▏     | 176/422 [00:00<00:00, 874.36it/s]14\t4922.88\t0.928\n 42%|████▏     | 179/422 [00:00<00:00, 892.20it/s]15\t4854.33\t0.931\n 21%|██        | 89/422 [00:00<00:00, 885.04it/s]16\t4733.85\t0.934\n 42%|████▏     | 178/422 [00:00<00:00, 881.75it/s]17\t4687.10\t0.937\n 42%|████▏     | 177/422 [00:00<00:00, 884.85it/s]18\t4642.98\t0.932\n 83%|████████▎ | 350/422 [00:00<00:00, 870.86it/s]19\t4676.57\t0.931\n"
    }
   ],
   "source": [
    "from thinc.api import Adam, fix_random_seed\n",
    "from tqdm.notebook import tqdm\n",
    "import ml_datasets\n",
    "from train import train_model\n",
    "\n",
    "fix_random_seed(0)\n",
    "optimizer = Adam(0.001)\n",
    "batch_size = 128\n",
    "data = (train_X, train_Y), (dev_X, dev_Y) = ml_datasets.mnist()\n",
    "\n",
    "\n",
    "print(\"Measuring performance across iterations:\")\n",
    "train_model(data, model, optimizer, 20, batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is a definition for a text classification network, which expects a *list of arrays as input*, where each array should have two columns with different numeric identifier features. \n",
    "\n",
    "The model takes a list of 2-dimensional arrays (the tokenized texts mapped to vocab IDs) and outputs a 2d array.\n",
    "\n",
    "The two features will be embedded using separate embedding tables, and the two vectors added and passed through a `Maxout` layer with layer `normalization` and `dropout`. The sequences then pass through two `pooling` functions, and the `concatenated` results are passed through 2 `Relu` layers with `dropout` and `residual` connections. Finally, the sequence vectors are passed through an output layer, which has a `Softmax` activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinc.api import add, chain, concatenate, clone\n",
    "from thinc.api import with_array, reduce_max, reduce_mean, residual\n",
    "from thinc.api import Model, Embed, Maxout, Softmax, Dropout\n",
    "\n",
    "nH = 5\n",
    "\n",
    "with Model.define_operators({\">>\": chain, \"|\": concatenate, \"+\": add, \"**\": clone}):\n",
    "    model = (\n",
    "        with_array(\n",
    "            (Embed(128, column=0) + Embed(64, column=1))\n",
    "            >> Maxout(nH, normalize=True, dropout=0.2)\n",
    "        )\n",
    "        >> (reduce_max() | reduce_mean())\n",
    "        >> residual(Relu() >> Dropout(0.2)) ** 2\n",
    "        >> Softmax()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from syntok.tokenizer import Tokenizer\n",
    "\n",
    "def load_data():\n",
    "    train_data, dev_data = ml_datasets.dbpedia(limit=2000)\n",
    "    train_texts, train_cats = zip(*train_data)\n",
    "    dev_texts, dev_cats = zip(*dev_data)\n",
    "    unique_cats = list(numpy.unique(numpy.concatenate((train_cats, dev_cats))))\n",
    "    nr_class = len(unique_cats)\n",
    "    print(f\"{len(train_data)} training / {len(dev_data)} dev\\n{nr_class} classes\")\n",
    "\n",
    "    train_y = numpy.zeros((len(train_cats), nr_class), dtype=\"f\")\n",
    "    for i, cat in enumerate(train_cats):\n",
    "        train_y[i][unique_cats.index(cat)] = 1\n",
    "    dev_y = numpy.zeros((len(dev_cats), nr_class), dtype=\"f\")\n",
    "    for i, cat in enumerate(dev_cats):\n",
    "        dev_y[i][unique_cats.index(cat)] = 1\n",
    "\n",
    "    train_tokenized = tokenize_texts(train_texts)\n",
    "    dev_tokenized = tokenize_texts(dev_texts)\n",
    "    # Generate simple vocab mapping, <unk> is 0\n",
    "    vocab = {}\n",
    "    count_id = 0\n",
    "    for text in train_tokenized:\n",
    "        for token in text:\n",
    "            if token not in vocab:\n",
    "                vocab[token] = count_id\n",
    "                count_id += 1\n",
    "    # Map texts using vocab\n",
    "    train_X = []\n",
    "    for text in train_tokenized:\n",
    "        train_X.append(numpy.array([vocab.get(t, 0) for t in text]))\n",
    "    dev_X = []\n",
    "    for text in dev_tokenized:\n",
    "        dev_X.append(numpy.array([vocab.get(t, 0) for t in text]))\n",
    "    return (train_X, train_y), (dev_X, dev_y), vocab, train_texts, dev_texts\n",
    "\n",
    "\n",
    "def tokenize_texts(texts):\n",
    "    tok = Tokenizer()\n",
    "    return [[token.value for token in tok.tokenize(text)] for text in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y), (dev_X, dev_y), vocab, train_texts, dev_texts = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(data, model, optimizer, 20, batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}