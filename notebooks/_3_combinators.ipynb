{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Useful `combinator` functions\n",
    "\n",
    "We can apply clone to model instances that have child layers, making it easy to define more complex architectures. \n",
    "For instance, we often want to attach an activation function and dropout to a linear layer, and then repeat that \n",
    "substructure a number of times. Of course, you can make whatever intermediate functions you find helpful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install \"thinc>=8.0.0a0\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy\n",
    "from thinc.api import (Linear, \n",
    "                       chain, \n",
    "                       concatenate, \n",
    "                       clone, \n",
    "                       glorot_uniform_init, \n",
    "                       zero_init,\n",
    "                       Relu, \n",
    "                       Dropout,\n",
    "                       with_array)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `chain` function wires two model instances together, with a feed-forward relationship."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_hidden = 128\n",
    "X = numpy.zeros((128, 16), dtype=\"f\")\n",
    "Y = numpy.zeros((128, 10), dtype=\"f\")\n",
    "\n",
    "model = chain(Linear(n_hidden, init_W=glorot_uniform_init), Linear(init_W=zero_init),)\n",
    "model.initialize(X=X, Y=Y)\n",
    "nI = model.get_dim(\"nI\")\n",
    "nO = model.get_dim(\"nO\")\n",
    "nO_hidden = model.layers[0].get_dim(\"nO\")\n",
    "print(f\"Initialized model with input dimension nI={nI} and output dimension nO={nO}.\")\n",
    "print(f\"The size of the hidden layer is {nO_hidden}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `concatenate` combinator produces a layer that runs the child layers separately, and then concatenates\n",
    "their outputs together. This is often useful for combining features from different sources.  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "model = concatenate(Linear(n_hidden), Linear(n_hidden))\n",
    "model.initialize(X=X)\n",
    "\n",
    "ni_layer_0 = model.layers[0].get_dim(\"nI\")\n",
    "no_layer_0 = model.layers[0].get_dim(\"nO\")\n",
    "print(f\"The input size of the hidden layer 0 is {ni_layer_0}.\")\n",
    "print(f\"The output size of the hidden layer 0 is {no_layer_0}.\")\n",
    "\n",
    "ni_layer_1 = model.layers[1].get_dim(\"nI\")\n",
    "no_layer_1 = model.layers[1].get_dim(\"nO\")\n",
    "print(f\"The input size of the hidden layer 1 is {ni_layer_1}.\")\n",
    "print(f\"The output size of the hidden layer 1 is {no_layer_1}.\")\n",
    "\n",
    "nI = model.get_dim(\"nI\")\n",
    "nO = model.get_dim(\"nO\")\n",
    "nO_hidden = model.layers[0].get_dim(\"nO\")\n",
    "\n",
    "print(f\"Initialized model with input dimension nI={nI}.\")\n",
    "print(f\"Initialized model with output dimension nO={nO}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `clone` combinator creates a number of copies of a layer, and chains them together into a \n",
    "deep feed-forward network.\n",
    "\n",
    "The shape inference is especially handy here: we want the first and last layers to have different shapes, \n",
    "so we can avoid providing any dimensions into the layer we clone. We then just have to specify the \n",
    "first layer's output size, and we can let the rest of the dimensions be inferred from the data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = clone(Linear(), 5)\n",
    "model.layers[0].set_dim(\"nO\", n_hidden)\n",
    "model.initialize(X=X, Y=Y)\n",
    "nI = model.get_dim(\"nI\")\n",
    "nO = model.get_dim(\"nO\")\n",
    "print(f\"Initialized model with input dimension nI={nI} and output dimension nO={nO}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can apply clone to model instances that have child layers, making it easy to define more \n",
    "complex architectures. For instance, we often want to attach an *activation function* and *dropout* to \n",
    "a linear layer, and then repeat that substructure a number of times. \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def MyCustomLayer(dropout=0.2):\n",
    "    return chain(Linear(), Relu(), Dropout(dropout))\n",
    "\n",
    "model = clone(MyCustomLayer(0.2), 5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Thinc also provides several *input and output transformation* combinators as unary functions.\n",
    "\n",
    "The `with_array` combinator produces a model that *flattens lists of arrays* into a single array, \n",
    "and then *calls the child layer* to get the flattened output. It then *reverses* the transformation on \n",
    "the output.\n",
    "\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nI=4\n",
    "nO=2\n",
    "n_instances=10\n",
    "\n",
    "model = with_array(Linear(nO, nI))\n",
    "\n",
    "# allocate a 10 instances of 2-dimensional arrays of float elements\n",
    "Xs = [model.ops.alloc2f(n_instances, nI, dtype=\"f\")]\n",
    "\n",
    "model.initialize(X=Xs)\n",
    "Ys = model.predict(Xs)\n",
    "print(f\"Prediction shape: {Ys[0].shape}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What it does is effectively compute `numpy.hstack()` on the input arrays before passing in to the child layer.\n",
    "However, it worth mentioning the first array's dimension dictates the size of the transformation.\n",
    "Thus, the feature dimension should match. \n",
    "For example:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = with_array(Linear(nO, nI))\n",
    "\n",
    "# allocate 2\n",
    "Xs = [model.ops.alloc2f(6, nI, dtype=\"f\"), model.ops.alloc2f(9, nI, dtype=\"f\")]\n",
    "\n",
    "print(\"Xs:\")\n",
    "print(Xs)\n",
    "\n",
    "print(f\"first array shape '{Xs[0].shape}' and type '{type(Xs[0])}'\")\n",
    "print(\"The first array:\")\n",
    "print(Xs[0])\n",
    "print(\"---\")\n",
    "print(f\"second array shape '{Xs[1].shape}' and type '{type(Xs[1])}'\")\n",
    "print(\"The second array:\")\n",
    "print(Xs[1])\n",
    "\n",
    "model.initialize(X=Xs)\n",
    "Ys = model.predict(Xs)\n",
    "print(f\"Prediction shape will be: {Ys[0].shape}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}