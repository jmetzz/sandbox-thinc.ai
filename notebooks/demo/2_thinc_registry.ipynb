{
 "cells": [
  {
   "source": [
    "# Prepare the environment\n",
    "\n",
    "Install the dependencies and import the necessary packages.\n",
    "\n",
    "> GraphViz must be installed in your system in order to visualize the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install \"thinc>=8.0.0a0\" ml_datasets \"tqdm>=4.41\" pydot graphviz svgwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from typing import Union, Iterable\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "import pydot\n",
    "from IPython.display import SVG, display\n",
    "\n",
    "import thinc\n",
    "from thinc.api import chain, Relu, Softmax, Config, registry\n",
    "from thinc.types import FloatsXd\n",
    "\n",
    "import ml_datasets\n"
   ]
  },
  {
   "source": [
    "# Utility functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(data, model, optimizer, n_iter, batch_size):\n",
    "    (train_X, train_Y), (test_X, test_Y) = data\n",
    "    for i in range(n_iter):\n",
    "        batches = model.ops.multibatch(batch_size, train_X, train_Y, shuffle=True)\n",
    "        for X, Y in tqdm(batches, leave=False):\n",
    "            Yh, backprop = model.begin_update(X)\n",
    "            backprop(Yh - Y)\n",
    "            model.finish_update(optimizer)\n",
    "        # Evaluate and print progress\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for X, Y in model.ops.multibatch(batch_size, test_X, test_Y):\n",
    "            Yh = model.predict(X)\n",
    "            correct += (Yh.argmax(axis=1) == Y.argmax(axis=1)).sum()\n",
    "            total += Yh.shape[0]\n",
    "        score = correct / total\n",
    "        print(f\" {i} {float(score):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_label(layer):\n",
    "    layer_name = layer.name\n",
    "    nO = layer.get_dim(\"nO\") if layer.has_dim(\"nO\") else \"?\"\n",
    "    nI = layer.get_dim(\"nI\") if layer.has_dim(\"nI\") else \"?\"\n",
    "    return f\"{layer.name}|({nI}, {nO})\".replace(\">\", \"&gt;\")\n",
    "\n",
    "def visualize_model(model):\n",
    "    dot = pydot.Dot()\n",
    "    dot.set(\"rankdir\", \"LR\")\n",
    "    dot.set_node_defaults(shape=\"record\", fontname=\"arial\", fontsize=\"10\")\n",
    "    dot.set_edge_defaults(arrowsize=\"0.7\")\n",
    "    nodes = {}\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        label = get_label(layer)\n",
    "        node = pydot.Node(layer.id, label=label)\n",
    "        dot.add_node(node)\n",
    "        nodes[layer.id] = node\n",
    "        if i == 0:\n",
    "            continue\n",
    "        from_node = nodes[model.layers[i - 1].id]\n",
    "        to_node = nodes[layer.id]\n",
    "        if not dot.get_edge(from_node, to_node):\n",
    "            dot.add_edge(pydot.Edge(from_node, to_node))\n",
    "    display(SVG(dot.create_svg()))"
   ]
  },
  {
   "source": [
    "# Create and register a custom optmizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyCoolOptimizer():\n",
    "    def __init__(self, learn_rate: float, gamma: Iterable[float]):\n",
    "        self.eta = learn_rate\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"MyCoolOptimizer(eta={self.eta}, gamma={self.gamma})\"\n",
    "\n",
    "    def __call__(self, weights: FloatsXd, gradient: FloatsXd):\n",
    "        \"\"\"Call the optimizer with weights and a gradient. The key is the\n",
    "        identifier for the parameter, usually the node ID and parameter name.\n",
    "        \"\"\"\n",
    "        # the optimization logic goes here :)\n",
    "        param, grad =  self._my_cool_logic(weights, gradient)\n",
    "        return param, grad\n",
    "\n",
    "    def _my_cool_logic(self, weights, gradient):\n",
    "        #dummy placeholder\n",
    "        pass\n",
    "\n",
    "\n",
    "op = MyCoolOptimizer(2.0, 3.0)\n",
    "print(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@thinc.registry.optimizers.register(\"my_cool_optimizer.v1\")\n",
    "def make_my_optimizer(learn_rate: Union[float, Iterable[float]], gamma: float):\n",
    "    return MyCoolOptimizer(learn_rate, gamma)\n",
    "\n",
    "# Later you can retrieve your function by name:\n",
    "create_optimizer = thinc.registry.optimizers.get(\"my_cool_optimizer.v1\")\n",
    "create_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@thinc.registry.schedules(\"my_cool_decaying_schedule.v1\")\n",
    "def decaying(base_rate: float, decay: float, *, t: int = 0) -> Iterable[float]:\n",
    "    while True:\n",
    "        yield base_rate * (1.0 / (1.0 + decay * t))\n",
    "        t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = \"\"\"[optimizer]\n",
    "@optimizers = \"my_cool_optimizer.v1\"\n",
    "gamma = 1e-8\n",
    "\n",
    "[optimizer.learn_rate]\n",
    "@schedules = \"my_cool_decaying_schedule.v1\"\n",
    "base_rate = 0.001\n",
    "decay = 1e-4\n",
    "\"\"\"\n",
    "\n",
    "config = Config().from_str(CONFIG)\n",
    "C = registry.make_from_config(config)\n",
    "C['optimizer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable positional arguments example\n",
    "\n",
    "In some cases your registered function may accept variable positional arguments. In your config, you can then use `*` to define a list of values:\n",
    "\n",
    "```yaml\n",
    "[schedule]\n",
    "@schedules = \"my_cool_schedule.v1\"\n",
    "* = [0.05, 0.1, 0.25, 0.75, 0.9]\n",
    "final = 1.0\n",
    "```\n",
    "\n",
    "\n",
    "> Type hints for variable arguments should always describe the type of the individual arguments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@thinc.registry.schedules(\"my_cool_schedule.v1\")\n",
    "def schedule(*steps: float, final: float = 1.0) -> Iterable[float]:\n",
    "    yield from steps\n",
    "    while True:\n",
    "        yield final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG= \"\"\"[optimizer]\n",
    "@optimizers = \"my_cool_optimizer.v1\"\n",
    "gamma = 1e-8\n",
    "\n",
    "[optimizer.learn_rate]\n",
    "@schedules = \"my_cool_decaying_schedule.v1\"\n",
    "base_rate = 0.001\n",
    "decay = 1e-4\n",
    "\n",
    "[schedule]\n",
    "@schedules = \"my_cool_schedule.v1\"\n",
    "* = [0.05, 0.1, 0.25, 0.75, 0.9]\n",
    "final = 1.0\n",
    "\"\"\"\n",
    "config = Config().from_str(CONFIG)\n",
    "C = registry.make_from_config(config)\n",
    "my_schedule = C['schedule']\n",
    "my_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 10 elements of the `schedule` object\n",
    "list(itertools.islice(my_schedule, 10))"
   ]
  },
  {
   "source": [
    "# Register a model\n",
    "\n",
    "If you've written a layer or model definition you're happy with, you can use Thinc's function registry to register it and assign it a string name. Your function can take any arguments that can later be defined in the config. Adding **type hints** ensures that config settings will be **parsed and validated** before they're passed into the function, so you don't end up with incompatible settings and confusing failures later on. Here's the MNIST model, defined as a custom layer:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@thinc.registry.layers(\"MNIST.v1\")\n",
    "def create_mnist(nO: int, dropout: float) -> thinc.model.Model:\n",
    "    return chain(\n",
    "        Relu(nO, dropout=dropout), \n",
    "        Relu(nO, dropout=dropout), \n",
    "        Softmax()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the config, we can now refer to it by name and set its arguments. This makes the config maintainable and compact, while still allowing you to change and record the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = \"\"\"\n",
    "[model]\n",
    "@layers = \"MNIST.v1\"\n",
    "nO = 32\n",
    "dropout = 0.2\n",
    "\n",
    "[optimizer]\n",
    "@optimizers = \"Adam.v1\"\n",
    "learn_rate = 0.001\n",
    "\n",
    "[training]\n",
    "n_iter = 10\n",
    "batch_size = 128\n",
    "\"\"\"\n",
    "\n",
    "config = Config().from_str(CONFIG)\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also wrap the dataset in a registry function.\n",
    "Before make sure you have all the dependencies settled. For this example, install the `ml_datasets` package and import all the objects used in the configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@thinc.registry.datasets(\"mnist_data.v1\")\n",
    "def mnist():\n",
    "    return ml_datasets.mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = \"\"\"\n",
    "[model]\n",
    "@layers = \"MNIST.v1\"\n",
    "nO = 32\n",
    "dropout = 0.2\n",
    "\n",
    "[optimizer]\n",
    "@optimizers = \"Adam.v1\"\n",
    "learn_rate = 0.001\n",
    "\n",
    "[training]\n",
    "n_iter = 10\n",
    "batch_size = 128\n",
    "\n",
    "[training.data]\n",
    "@datasets = \"mnist_data.v1\"\n",
    "\"\"\"\n",
    "\n",
    "config = Config().from_str(CONFIG)\n",
    "loaded_config = registry.make_from_config(config)\n",
    "loaded_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now you can use the objects in the registry:\n",
    "model = loaded_config[\"model\"]\n",
    "optimizer = loaded_config[\"optimizer\"]\n",
    "n_iter = loaded_config[\"training\"][\"n_iter\"]\n",
    "batch_size = loaded_config[\"training\"][\"batch_size\"]\n",
    "data = (train_X, train_Y), (dev_X, dev_Y) = loaded_config[\"training\"][\"data\"]\n",
    "\n",
    "# After loading the data from config, they might still need to be moved to the right device\n",
    "train_X = model.ops.asarray(train_X)\n",
    "train_Y = model.ops.asarray(train_Y)\n",
    "dev_X = model.ops.asarray(dev_X)\n",
    "dev_Y = model.ops.asarray(dev_Y)\n",
    "\n",
    "model.initialize(X=train_X[:5], Y=train_Y[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_model(data, model, optimizer, n_iter, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}